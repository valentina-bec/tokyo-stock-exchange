{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/corneliusbohle/Desktop/tokyo/tokyo-stock-exchange/.capstone/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "# importing required packages\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.figsize':(9,3), 'figure.dpi':120})\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "import numpy as np\n",
    "import warnings\n",
    "import statistics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train and test data\n",
    "test = pd.read_csv('model_data/model_test.csv')\n",
    "train = pd.read_csv('model_data/model_train.csv')\n",
    "prophet_predictions = pd.read_csv('prophet_predictions/predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks that did not work for modelling\n",
    "banned_stocks = [9755, 4686, 6058, 6502, 6815]\n",
    "# test data with out these stocks\n",
    "test_wo_errors = test.query('SecuritiesCode not in @banned_stocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of industries models already exist for\n",
    "industries_with_models = [\"ENERGY RESOURCES \", \"PHARMACEUTICAL \", \"BANKS \", \"FINANCIALS （EX BANKS） \", \"COMMERCIAL & WHOLESALE TRADE \", \"CONSTRUCTION & MATERIALS \", \"ELECTRIC POWER & GAS \", \"AUTOMOBILES & TRANSPORTATION EQUIPMENT \", \"IT & SERVICES, OTHERS \", \"RETAIL TRADE \", \"REAL ESTATE \", \"FOODS \", \"ELECTRIC APPLIANCES & PRECISION INSTRUMENTS \", \"MACHINERY \", \"STEEL & NONFERROUS METALS \", \"RAW MATERIALS & CHEMICALS \", \"TRANSPORTATION & LOGISTICS \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(test, amount, number):\n",
    "    '''\n",
    "    Input: Testdata, amount of money to invest, number of stocks to buy/short\n",
    "    Output: Performance of an equally weighted ETF, Performance of the Stocks recommended by the model\n",
    "    '''\n",
    "    \n",
    "    # determine number of days to predict\n",
    "    days = test.Date.nunique()\n",
    "    \n",
    "    # calling make_predictions function\n",
    "    predictions_df = make_predictions(test, days)\n",
    "\n",
    "    # calling eval function\n",
    "    eval(test, predictions_df, amount, number)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2696066977.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [6]\u001b[0;36m\u001b[0m\n\u001b[0;31m    train = pd.DataFrame()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def create_train_test(df, split):\n",
    "\n",
    "\n",
    "   '''\n",
    "   Input: DataFrame of stock data, split of test data\n",
    "   Output: Train data, test data\n",
    "   '''\n",
    "\n",
    "    # creating two empty dataframes for train and test data\n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "\n",
    "        # looping through SecurityCodes\n",
    "    for i in df.SecuritiesCode.unique():\n",
    "        # making two querys for the code with test being the length of split\n",
    "        train_query = df.query('SecuritiesCode == @i')[:-split]\n",
    "        test_query = df.query('SecuritiesCode == @i')[-split:]\n",
    "\n",
    "        # adding the querys to the dataframes\n",
    "        train = pd.concat([train, train_query])\n",
    "        test = pd.concat([test, test_query])\n",
    "\n",
    "        # returning training and test data frames\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(df, model):\n",
    "\n",
    "    '''Input: data of one stock\n",
    "       Output: performance of the stock in the given timeframe\n",
    "       '''\n",
    "    # getting performance for predicted values\n",
    "    if model == True:\n",
    "        # making new list for different performances\n",
    "        performances = []\n",
    "\n",
    "        # getting starting and end price, calculating performance of the lower predictions and adding it to list\n",
    "        start_lower = df.ad_Close_lower.to_list()[0]\n",
    "        end_lower = df.ad_Close_lower.to_list()[-1]\n",
    "        performance_lower = (end_lower - start_lower) / start_lower\n",
    "        performances.append(performance_lower)\n",
    "\n",
    "        # getting starting and end price, calculating performance of the midlle predictions and adding it to list\n",
    "        start_mid = df.ad_Close.to_list()[0]\n",
    "        end_mid = df.ad_Close.to_list()[-1]\n",
    "        performance_mid = (end_mid - start_mid) / start_mid\n",
    "        performances.append(performance_mid)\n",
    "\n",
    "        # getting starting and end price, calculating performance of the upper predictions and adding it to list\n",
    "        start_upper = df.ad_Close_upper.to_list()[0]\n",
    "        end_upper = df.ad_Close_upper.to_list()[-1]\n",
    "        performance_upper = (end_upper - start_upper) / start_upper\n",
    "        performances.append(performance_upper)\n",
    "\n",
    "        # calculating mean performance\n",
    "        performance_mean = np.mean(performances)\n",
    "\n",
    "        # returning mean performance and performance of middle predictions\n",
    "        return performance_lower, performance_mid\n",
    "    \n",
    "    # calculating return for actual values\n",
    "    elif model == False:\n",
    "\n",
    "        # getting start and end price, calculating performance and returning it\n",
    "        start = df.ad_Close.to_list()[0]\n",
    "        end = df.ad_Close.to_list()[-1]\n",
    "        performance = (end - start) / start\n",
    "\n",
    "        return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etf_performance(test, predictions, amount):\n",
    "\n",
    "    '''Input: test data, predictions of the stocks, amount of money to invest\n",
    "    Output: Percentage and absolute return of an equally weighted ETF of all stocks that were predicted'''\n",
    "\n",
    "    # making list for performances\n",
    "    performances = []\n",
    "\n",
    "    # looping through stocks\n",
    "    for i in predictions.SecuritiesCode.unique():\n",
    "        \n",
    "        # making query of the test data for one stock, sorting it by Date, calling performance function and adding it to list\n",
    "        query = test.query('SecuritiesCode == @i').reset_index()\n",
    "        query = query.sort_values('Date')\n",
    "        performance = get_performance(query, False)\n",
    "        performances.append(performance)\n",
    "\n",
    "    # calculating mean return stocks and absolute return given invested amount\n",
    "    pct_return = np.mean(performances)\n",
    "    abs_return = amount * pct_return\n",
    "\n",
    "    # returning percentage and absolute return of ETF containing all stocks in test data\n",
    "    return pct_return, abs_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(test, predictions, amount, number):\n",
    "\n",
    "    '''Input: test data, predictions of stocks, amount of money to invest, number of stocks to buy/ short\n",
    "    Ouput: percentage and absolute return of stocks recommended to buy/short by the model in the given timeframe'''\n",
    "\n",
    "    # creating dataframe for predicted performances\n",
    "    df_performances = pd.DataFrame()\n",
    " \n",
    "    # looping through stocks in test data\n",
    "    for i in test.SecuritiesCode.unique():\n",
    "        \n",
    "        # making query of predictions for one stock, getting performances and adding stock and performances to dataframe\n",
    "        query = predictions.query('SecuritiesCode == @i')\n",
    "        performance_mid, performance_mean = get_performance(query, True)\n",
    "        df_code = pd.DataFrame({'SecuritiesCode': [i], 'performance_mid': [performance_mid],  'performance_mean': [performance_mean]})\n",
    "        df_performances = pd.concat([df_performances, df_code])\n",
    "\n",
    "    # saving dataframe\n",
    "    df_performances.to_csv('prophet_predictions/performance_predictions.csv')\n",
    "\n",
    "    # getting n best and worst stocks according to predictions by sorting dataframe by performance\n",
    "    best = df_performances.sort_values('performance_mean', ascending=False).SecuritiesCode.to_list()[:number]\n",
    "    worst = df_performances.sort_values('performance_mean', ascending=False).SecuritiesCode.to_list()[-number :]\n",
    "\n",
    "    # making list for actual performances of recommended stocks\n",
    "    chosen = []\n",
    "\n",
    "    # looping through best stocks according to predictions\n",
    "    for i in best:\n",
    "\n",
    "        # making query of the stock from test data, getting actual performance and adding it to list\n",
    "        query = test.query('SecuritiesCode == @i').reset_index()\n",
    "        query = query.sort_values('Date')\n",
    "        performance = get_performance(query, False)\n",
    "        chosen.append(performance)\n",
    "    \n",
    "    # looping through worst stocks according to predictions\n",
    "    for i in worst:\n",
    "\n",
    "        # making query of the stock from test data, getting actual performance, multiplying it with -1 (return is inverse to performance when shorting) and adding it to list\n",
    "        query = test.query('SecuritiesCode == @i').reset_index()\n",
    "        query = query.sort_values('Date')\n",
    "        performance = get_performance(query,False)\n",
    "        short = performance * -1\n",
    "        chosen.append(short)\n",
    "\n",
    "    # calculating return of basket of recommended stocks and absolute return given invested amount\n",
    "    pct_return = np.mean(chosen)\n",
    "    abs_return = amount * pct_return\n",
    "\n",
    "    # returning percentage and absolute return\n",
    "    return pct_return, abs_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(test, predictions, amount, number):\n",
    "\n",
    "    '''Input: test data of stocks, predictions of stocks, amount of money to invest, number of stocks to buy/short\n",
    "    Output: Percentage and absolute return of an equally weighted ETF of all predicted stocks and of the stocks recommended by the model and the difference between ETF and model'''\n",
    "    \n",
    "    # getting returns of model and ETF, calculating starting and end value of invested money\n",
    "    pct_model, abs_model = model_performance(test, predictions, amount, number)\n",
    "    model_value = amount + abs_model\n",
    "    pct_etf, abs_etf = etf_performance(test, predictions, amount)\n",
    "    etf_value = amount + abs_etf\n",
    "\n",
    "    # calculating difference of model and ETF\n",
    "    pct_difference = (pct_model - pct_etf) / pct_etf * 100\n",
    "    abs_difference = abs_model - abs_etf\n",
    "    \n",
    "    # printing results\n",
    "    print('Model Performance: ', pct_model*100)\n",
    "    print('entry_value: ', amount, 'end_value: ', model_value)\n",
    "\n",
    "    print('ETF Performance: ', pct_etf*100)\n",
    "    print('entry_value: ', amount, 'end_value: ', etf_value)\n",
    "\n",
    "    print('The percentage difference is ', pct_difference , '%')\n",
    "    print('The absolute difference is ', abs_difference, ' JPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_mean(a, b):\n",
    "\n",
    "    '''Input: two lists\n",
    "    Output: mean of the two lists'''\n",
    "\n",
    "    result = [(g + h) / 2 for g, h in zip(a, b)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prophet(train, c_range, interval, scale):\n",
    "\n",
    "    '''training data on one stock, different hyperparamteters\n",
    "    Output: mape of the model, model'''\n",
    "    \n",
    "    # getting columns and from training data and renaming them\n",
    "    train = train[['Date', 'ad_Close']]\n",
    "    train.columns = ['ds', 'y']\n",
    "\n",
    "    # creating model and fitting it to train data\n",
    "    m = Prophet(growth='linear', changepoint_range= c_range, interval_width=interval, changepoint_prior_scale=scale,  uncertainty_samples=1000, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False).add_seasonality(name = 'yearly', period=245, fourier_order=12).add_seasonality(name='monthly', period=24, fourier_order=4).add_seasonality(name='weekly', period=5, fourier_order=5)\n",
    "    model = m.fit(train, verbose=0)\n",
    "    \n",
    "    # creating dataframe of predictions for only train data\n",
    "    future = model.make_future_dataframe(periods=0)\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # getting the middle prediction\n",
    "    mid = forecast.yhat.to_list()\n",
    "   \n",
    "    # making sure predictions and actual values have same length\n",
    "    if len(mid) == len(train.y):\n",
    "        mape_mid = mape(train.y, mid)\n",
    "        \n",
    "        # returning mape of model and model\n",
    "        return mape_mid, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(train, c_range_grid, interval_grid, scale_grid):\n",
    "\n",
    "    '''Input: training data on different stocks, grids on different hyperparameters of FB prophet\n",
    "    Ouput: model for each stock, dataframe of each stock and score of the model'''\n",
    "\n",
    "    # setting grids for hyperparameters\n",
    "    a = c_range_grid\n",
    "    b = interval_grid\n",
    "    c = scale_grid\n",
    "\n",
    "    # creating data frame and list for results\n",
    "    paths_df = pd.DataFrame()\n",
    "    results = []\n",
    "\n",
    "    # looping through stocks\n",
    "    for i in tqdm(train.SecuritiesCode.unique()):\n",
    "\n",
    "        # creating train data for stock\n",
    "        code_train = train.query('SecuritiesCode == @i')\n",
    "        \n",
    "        # making lists for scores and models of stock\n",
    "        scores = []\n",
    "        models = []\n",
    "\n",
    "        # looping through parameter values\n",
    "        for s in a:\n",
    "            for m in b:\n",
    "                for x in c:\n",
    "\n",
    "                    # setting parameter values\n",
    "                    c_range = s\n",
    "                    interval = m\n",
    "                    scale = x\n",
    "                    \n",
    "                    # getting score and model by calling prophet function\n",
    "                    score, model = prophet(code_train, s, m, x)\n",
    "\n",
    "                    # adding score and model to lists\n",
    "                    scores.append(score)\n",
    "                    models.append(model)\n",
    "\n",
    "        # getting best score and adding it to list, its index and best model through the index\n",
    "        best_score = np.min(scores)\n",
    "        results.append(best_score)\n",
    "        indx = scores.index(best_score)\n",
    "        best_model = models[indx]\n",
    "\n",
    "        # saving model\n",
    "        model_name = 'models/prophet_' + str(i) + '.pkl'\n",
    "        pickle.dump(best_model, open(model_name, 'wb'))\n",
    "           \n",
    "        # adding results to dataframe   \n",
    "        df_code = pd.DataFrame()\n",
    "        df_code['SecuritiesCode'] = [i]\n",
    "        df_code['score'] = [best_score]\n",
    "        paths_df = pd.concat([paths_df, df_code])\n",
    "    \n",
    "    result = np.mean(results)\n",
    "    paths_df = paths_df.reset_index()\n",
    "\n",
    "    # returning dataframe\n",
    "    return paths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(code, days):\n",
    "\n",
    "    '''Input: SecuritiesCode of a stock, number of days to be predicted\n",
    "    Output: Predictions of the given timeframe'''\n",
    "\n",
    "    # loading model for stock\n",
    "    model = pickle.load(open(f'models/prophet_{code}.pkl', 'rb'))\n",
    "\n",
    "    # making dataframe with predictions for certain timeframe\n",
    "    future = model.make_future_dataframe(periods=days)\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # getting different predictions from dataframe\n",
    "    lower = forecast.yhat_lower.tail(days).to_list()\n",
    "    upper = forecast.yhat_upper.tail(days).to_list()\n",
    "    mid = forecast.yhat.tail(days).to_list()\n",
    "    mid_lower = list_mean(lower, mid)\n",
    "    mid_upper = list_mean(upper, mid)\n",
    "\n",
    "    # returning predictions\n",
    "    return lower, mid, upper\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(test, days):\n",
    "\n",
    "    '''Input: test data, number of days to be predicted\n",
    "    Output: Dataframe of predictions of all stocks in the test data'''\n",
    "\n",
    "    # creating dataframe for predictions and date index\n",
    "    predictions_df = pd.DataFrame()\n",
    "    date_index = test.Date.unique()\n",
    "\n",
    "    # looping through stocks\n",
    "    for i in test.SecuritiesCode.unique():\n",
    "\n",
    "        # getting predictions by calling get_prediction function\n",
    "        lower, mid, upper = get_prediction(i, days)\n",
    "\n",
    "        # making predictions dataframe for stock and adding it to large dataframe\n",
    "        df_code = pd.DataFrame({'Date': date_index, 'SecuritiesCode': i, 'ad_Close_lower': lower, 'ad_Close': mid, 'ad_Close_upper': upper})\n",
    "        predictions_df = pd.concat([predictions_df, df_code])\n",
    "\n",
    "        # saving dataframe\n",
    "        predictions_df.to_csv('prophet_predictions/predictions.csv')\n",
    "\n",
    "    # returning dataframe\n",
    "    return predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mape(test, predictions):\n",
    "    \n",
    "    # creating dataframe for performances\n",
    "    mape_performance = pd.DataFrame()\n",
    "\n",
    "    # looping through stocks\n",
    "    for i in test.SecuritiesCode.unique():\n",
    "\n",
    "        # getting test data and predictions for stock\n",
    "        test_query = test.query('SecuritiesCode == @i')\n",
    "        pred_query = predictions.query('SecuritiesCode == @i')\n",
    "\n",
    "        # getting price columns\n",
    "        test_price = test_query.ad_Close.to_list()\n",
    "        pred_price_mid = pred_query.ad_Close.to_list()\n",
    "\n",
    "        # calculating mape scores over different time periods\n",
    "        mape_24 = mape(test_price, pred_price_mid)\n",
    "        mape_10 = mape(test_price[:10], pred_price_mid[:10])\n",
    "        mape_3 = mape(test_price[:3], pred_price_mid[:3])\n",
    "        mape_1 = mape(test_price[:1], pred_price_mid[:1])\n",
    "        mape_end = mape(test_price[-1:], pred_price_mid[-1:])\n",
    "\n",
    "        # creating performance dataframe for stock and adding it to large dataframe\n",
    "        df_code = pd.DataFrame({'SecuritiesCode': [i], 'mape_24': [mape_24], 'mape_10': [mape_10], 'mape_3': [mape_3], 'mape_1': [mape_1], 'mape_end': mape_end})\n",
    "        mape_performance = pd.concat([mape_performance, df_code])\n",
    "\n",
    "    # returning dataframe\n",
    "    return mape_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_models(train, industry, c_range_grid, interval_grid, scale_grid):\n",
    "\n",
    "    '''Input: train data of several stocks, industry of the stocks to be modelled, grids on different hyperparameters of FB prophet\n",
    "    Ouput: models for each stock in the industry, dataframe of each stock and the score of the model'''\n",
    "\n",
    "    # getting train data for stocks of an industry\n",
    "    train_industry = train.query('Sector == @industry')\n",
    "\n",
    "    # getting result dataframe by calling grid_search function and saving it\n",
    "    paths_df = grid_search(train_industry, c_range_grid, interval_grid, scale_grid)\n",
    "    paths_df.to_csv(f'paths/{industry}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:  0.6372685702894354\n",
      "entry_value:  10000 end_value:  10063.726857028943\n",
      "ETF Performance:  -3.9961831885378696\n",
      "entry_value:  10000 end_value:  9600.381681146213\n",
      "The percentage difference is  -115.94693086436311 %\n",
      "The absolute difference is  463.3451758827305  JPY\n"
     ]
    }
   ],
   "source": [
    "eval(test_wo_errors, prophet_predictions, 10000, 100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0bc83a2a84f8a0c181d644628bbd7e2e7a747f8338e5cc86982252d7f4799ab2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('.capstone': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
