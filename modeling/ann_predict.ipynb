{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import datetime, time, os\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import  mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from functions import df_security_code\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (5, 5)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIFT = 24\n",
    "INPUT = 24\n",
    "OUT_STEPS = 24\n",
    "WINDOW = INPUT + OUT_STEPS\n",
    "LSTM = 32#32 #20 #30 #32 \n",
    "OPTIMIZER = 'scaler_Code ds'\n",
    "CONV_WIDTH = 3\n",
    "\n",
    "CODE = 8341\n",
    "\n",
    "PREDICT = 'all'\n",
    "date_from = datetime.date(2021, 9, 21)\n",
    "PREDICTIONS = 24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../data/curr_price_financial_fill.csv', parse_dates=['Date'], index_col=[0])\n",
    "raw_data.dropna(inplace=True)\n",
    "\n",
    "data = raw_data.query('Date > @date_from')\n",
    "\n",
    "del raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Date', 'SecuritiesCode', 'ExpectedDividend',\n",
    "       'SupervisionFlag', 'ad_Open', 'ad_High', 'ad_Low', 'ad_Close',\n",
    "       'ad_Volume', 'ad_Target', 'ad_Close_lag1', 'ad_Close_sma10',\n",
    "        'ad_Open_lag1', 'ad_Open_sma10',\n",
    "        'ad_High_lag1', 'ad_High_sma10',\n",
    "        'ad_Low_lag1', 'ad_Low_sma10',\n",
    "        'ad_Volume_lag1', 'ad_Volume_sma10', 'RSI', 'Return',\n",
    "       'macd', 'macd_h', 'macd_s', \n",
    "       'Volatility_week', 'Day_sin', 'Day_cos', 'Month_sin', 'Month_cos',\n",
    "       'Year_sin', 'Year_cos']\n",
    " \n",
    "data = data[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = data.SecuritiesCode.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 14:33:15.099506: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-12 14:33:15.100498: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at saved_model/baseline",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb#ch0000007?line=13'>14</a>\u001b[0m         models \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mbaseline\u001b[39m\u001b[39m'\u001b[39m: baseline, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb#ch0000007?line=14'>15</a>\u001b[0m              \u001b[39m'\u001b[39m\u001b[39mbaseline2\u001b[39m\u001b[39m'\u001b[39m: baseline2,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb#ch0000007?line=15'>16</a>\u001b[0m              \u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m: linear, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb#ch0000007?line=18'>19</a>\u001b[0m              \u001b[39m'\u001b[39m\u001b[39mlstm\u001b[39m\u001b[39m'\u001b[39m:lstm,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb#ch0000007?line=19'>20</a>\u001b[0m              \u001b[39m'\u001b[39m\u001b[39mfeedback\u001b[39m\u001b[39m'\u001b[39m:feedback}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb#ch0000007?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m models\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb#ch0000007?line=22'>23</a>\u001b[0m models \u001b[39m=\u001b[39m load_models()\n",
      "\u001b[1;32m/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb Cell 8'\u001b[0m in \u001b[0;36mload_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_models\u001b[39m():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb#ch0000007?line=1'>2</a>\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/cpu:0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb#ch0000007?line=2'>3</a>\u001b[0m     \u001b[39m# Load the saved model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb#ch0000007?line=4'>5</a>\u001b[0m         baseline \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39msaved_model/baseline\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb#ch0000007?line=5'>6</a>\u001b[0m         baseline2 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39msaved_model/baseline2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/valentina/ds/tokyo-stock-exchange/modeling/ann_predict.ipynb#ch0000007?line=6'>7</a>\u001b[0m         linear \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39msaved_model/linear\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/ds/tokyo-stock-exchange/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/valentina/ds/tokyo-stock-exchange/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/valentina/ds/tokyo-stock-exchange/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///Users/valentina/ds/tokyo-stock-exchange/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///Users/valentina/ds/tokyo-stock-exchange/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/valentina/ds/tokyo-stock-exchange/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/ds/tokyo-stock-exchange/.venv/lib/python3.9/site-packages/keras/saving/save.py:204\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/valentina/ds/tokyo-stock-exchange/.venv/lib/python3.9/site-packages/keras/saving/save.py?line=201'>202</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/valentina/ds/tokyo-stock-exchange/.venv/lib/python3.9/site-packages/keras/saving/save.py?line=202'>203</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> <a href='file:///Users/valentina/ds/tokyo-stock-exchange/.venv/lib/python3.9/site-packages/keras/saving/save.py?line=203'>204</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/valentina/ds/tokyo-stock-exchange/.venv/lib/python3.9/site-packages/keras/saving/save.py?line=205'>206</a>\u001b[0m   \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    <a href='file:///Users/valentina/ds/tokyo-stock-exchange/.venv/lib/python3.9/site-packages/keras/saving/save.py?line=206'>207</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(filepath_str, \u001b[39mcompile\u001b[39m, options)\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at saved_model/baseline"
     ]
    }
   ],
   "source": [
    "def load_models():\n",
    "    with tf.device('/cpu:0'):\n",
    "    # Load the saved model\n",
    "\n",
    "        baseline = tf.keras.models.load_model('saved_model/baseline')\n",
    "        baseline2 = tf.keras.models.load_model('saved_model/baseline2')\n",
    "        linear = tf.keras.models.load_model('saved_model/linear')\n",
    "        dense = tf.keras.models.load_model('saved_model/dense')\n",
    "        conv = tf.keras.models.load_model('saved_model/conv')\n",
    "        lstm = tf.keras.models.load_model('saved_model/lstm')\n",
    "        feedback = tf.keras.models.load_model('saved_model/feedback')\n",
    "\n",
    "\n",
    "        models = {'baseline': baseline, \n",
    "             'baseline2': baseline2,\n",
    "             'linear': linear, \n",
    "             'dense':dense ,\n",
    "             'conv':conv,\n",
    "             'lstm':lstm,\n",
    "             'feedback':feedback}\n",
    "\n",
    "    return models\n",
    "models = load_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Windows settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_window(features):\n",
    "\n",
    "    input_width=INPUT\n",
    "    label_width = OUT_STEPS\n",
    "    total_window_size = input_width +  label_width\n",
    "\n",
    "    input_slice = slice(0, input_width)  \n",
    "    label_start = total_window_size - label_width\n",
    "    labels_slice = slice(label_start, None)\n",
    "\n",
    "    inputs = features[:, input_slice, :]\n",
    "    labels = features[:, labels_slice, :]\n",
    "\n",
    "    inputs.set_shape([None, input_width, None])\n",
    "    labels.set_shape([None, label_width, None])\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFWindows():\n",
    "    def __init__(self, df=pd.DataFrame(), name='1', code=CODE):\n",
    "        self.window_size=int(WINDOW),\n",
    "        self.name = name\n",
    "        self.df = df,\n",
    "        self.possible_windows = df.shape[0] // WINDOW#  - 2*WINDOW \n",
    "        #display(self.possible_windows)\n",
    "        self.columns = df.columns\n",
    "        self.scaler = pickle.load(open(f'scaler/{CODE}_scaler.sav', 'rb'))\n",
    "        self.df_curr = self.first_window()\n",
    "        self.index_pred = None\n",
    "        pass\n",
    "    \n",
    "    def first_window(self):\n",
    "        return self.df[0].iloc[:WINDOW]\n",
    "        #return self.df[0].iloc[:INPUT]\n",
    "\n",
    "    def next_window(self, i):\n",
    "        # index next prediction\n",
    "        if i == 0:\n",
    "            self.df_curr = self.first_window()\n",
    "        self.df_curr = self.df_curr.iloc[:WINDOW+i]\n",
    "        #self.df_curr = self.df_curr.iloc[i:INPUT+i]\n",
    "        self.index_pred = self.df[0].iloc[INPUT + i:WINDOW + i].index\n",
    "\n",
    "        if not self.df_curr.shape[0] == WINDOW :\n",
    "            raise AssertionError(f' df len: {self.df_curr.shape[0]}')\n",
    "        return self.df_curr\n",
    "    \n",
    "\n",
    "    def make_dataset(self, df_):\n",
    "        #display(f'dataset len: {len(df_)}')\n",
    "        data = self.scaler.transform(df_)\n",
    "\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "        targets=None,\n",
    "        sequence_length=WINDOW,\n",
    "        sequence_stride=1,\n",
    "        shuffle=False,\n",
    "        batch_size=32,)\n",
    "\n",
    "        ds = ds.map(split_window)\n",
    "\n",
    "        return ds\n",
    "    \n",
    "    def update_df(self, pred):\n",
    "        \n",
    "        #display(f'curr: {len(self.df_curr[:OUT_STEPS].index)}')\n",
    "        \n",
    "        #display(f'pred: {len(pred.index)}')\n",
    "\n",
    "        self.df_curr = pd.concat([self.df_curr[:-(len(pred))], pred], axis=0)\n",
    "                #pred.query('@pred.index == @pred.index[0]')], axis=0)\n",
    "        pass\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_predict_unscale(win, data_set, model):\n",
    "    # predict\n",
    "    with tf.device('/cpu:0'):\n",
    "        pred = model.predict(data_set)\n",
    "    # transform back\n",
    "    df_pred = pd.DataFrame(win.scaler.inverse_transform(pred[len(pred) -1]))#\n",
    "    #print(df_pred)\n",
    "    #assert df_pred.shape[0] == INPUT\n",
    "    if not df_pred.shape[0] == INPUT:\n",
    "        raise AssertionError(df_pred.shape[0])\n",
    "    df_pred.columns = win.columns\n",
    "    df_pred.index = win.index_pred\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict one security\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_code = df_security_code(data, code=CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "sns.lineplot(data=data_code, y='ad_Close', x='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_code = df_security_code(data, code= CODE)\n",
    "df_code.drop(['SecuritiesCode'], axis=1, inplace=True)\n",
    "df_code = df_code.query('Date >= @date_from')\n",
    "df_code=df_code.set_index(['Date'])\n",
    "#assert len(df_code.columns) == 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_one = DFWindows(df_code, CODE)\n",
    "\n",
    "for i in range(0, win_one.possible_windows):\n",
    "    #print(i)\n",
    "    #win.df_curr\n",
    "    #create a window\n",
    "    df_win = win_one.next_window(i)\n",
    "    #df_win = win.first_window()\n",
    "    #print(df_win.shape)\n",
    "    win_ds = win_one.make_dataset(df_win)\n",
    "    \n",
    "    # predict window\n",
    "    win_pred = scale_predict_unscale(win_one, win_ds, models['linear'])\n",
    "\n",
    "    # update values for next prediction\n",
    "    win_one.update_df(win_pred)\n",
    "\n",
    "    #display(win.df_curr)\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.lineplot(data=data_code, y='ad_Close', x='Date')\n",
    "sns.lineplot(data=df_code, y='ad_Close', x='Date')\n",
    "sns.lineplot(data=win_one.df_curr, y='ad_Close', x=win_one.df_curr.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict with all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in list(models.keys()):#, linear, lstm]: \n",
    "        \n",
    "    if mod == 'feedback':continue\n",
    "    \n",
    "    win_one = DFWindows(df_code)\n",
    "    for i in range(0, win_one.possible_windows):\n",
    "\n",
    "        #create a window\n",
    "        df_win = win_one.next_window(i)\n",
    "\n",
    "        #make dataset\n",
    "        win_ds = win_one.make_dataset(df_win)\n",
    "        \n",
    "        # predict window\n",
    "        win_pred = scale_predict_unscale(win_one, win_ds, models[mod])\n",
    "        \n",
    "        # update values for next prediction\n",
    "        win_one.update_df(win_pred)\n",
    "\n",
    "    # evaluate\n",
    "\n",
    "    new = pd.concat([df_code['ad_Close'], win_one.df_curr['ad_Close'][-PREDICTIONS:]], axis=1, join='inner', keys=['origin', 'predict'])\n",
    "\n",
    "    mae = mean_absolute_percentage_error(new['origin'], new['predict'])*100\n",
    "    print(f'MAPE_{mod}: {mae:.2f}')\n",
    "        \n",
    "    plt.figure(figsize=(20,5))\n",
    "    sns.lineplot(data=df_code, y='ad_Close', x=df_code.index)\n",
    "    sns.lineplot(data=win_one.df_curr, y='ad_Close', x=win_one.df_curr.index,label=mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for several codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert PREDICT == 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('../data/curr_price_financial_fill.csv', parse_dates=['Date'],  index_col=[0])\n",
    "data = data_raw.query('Date > @date_from')\n",
    "del data_raw\n",
    "data = data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes =  data.SecuritiesCode.unique()\n",
    "\n",
    "results = {}\n",
    "\n",
    "predicts_df = pd.DataFrame()\n",
    "\n",
    "#codes = data.SecuritiesCode.unique()\n",
    "for sec in tqdm(codes):\n",
    "    df_code = df_security_code(data, sec)\n",
    "    df_code.drop(['SecuritiesCode'], axis=1, inplace=True)\n",
    "    df_code = df_code.query('Date >= @date_from ')\n",
    "    df_code=df_code.set_index(['Date'])\n",
    "    #assert len(df_code.columns) == 52\n",
    "    win_all = DFWindows(df_code)\n",
    "    if win_all.possible_windows < 1: continue\n",
    "    for name in list(models.keys()): \n",
    "        #if name == 'lstm': continue\n",
    "        if name == 'feedback': continue\n",
    "        \n",
    "        \n",
    "        for i in range(0, win_all.possible_windows):\n",
    "            \n",
    "            #create a window dataset\n",
    "            df_win = win_all.next_window(i)\n",
    "            win_ds = win_all.make_dataset(df_win)\n",
    "            \n",
    "            # predict window\n",
    "            win_pred = scale_predict_unscale(win_all, win_ds, models[name])\n",
    "\n",
    "            # update values for next prediction\n",
    "            win_all.update_df(win_pred)\n",
    " \n",
    "        # evaluate\n",
    "        \n",
    "        new = pd.concat([df_code['ad_Close'], win_all.df_curr['ad_Close'][-OUT_STEPS:]], axis=1, join='inner', keys=['origin', 'predict'])\n",
    "\n",
    "        mae = mean_absolute_percentage_error(new['origin'], new['predict'])*100\n",
    "\n",
    "        result_name =  '{}_{}'.format(str(sec), str(name))\n",
    "        results[result_name] = round(mae,2)\n",
    "        #print(f'{result_name}: {mae:.2f}')\n",
    "\n",
    "        win_all.df_curr['SecuritiesCode'] = sec\n",
    "        win_all.df_curr['Model'] = name\n",
    "        predicts_df= pd.concat([predicts_df, win_all.df_curr], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results, index=[0]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_df.to_csv('../data/allpreds_24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predicts_df[['Model', 'SecuritiesCode','ad_Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = data[['Date', 'SecuritiesCode','ad_Close']]\n",
    "real['Model'] = str('real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.reset_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date_pred = pred.Date\n",
    "\n",
    "print(f'Predictions: ')\n",
    "print('------'*10)\n",
    "print(f'from: {date_pred.min().strftime(\"%d-%m-%Y\") }')\n",
    "print(f'to  : {date_pred.max().strftime(\"%d-%m-%Y\") }')\n",
    "\n",
    "print(f'      {date_pred.nunique()} days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "real_pred = real.Date\n",
    "\n",
    "print(f'Predictions: ')\n",
    "print('------'*10)\n",
    "print(f'from: {real_pred.min().strftime(\"%d-%m-%Y\") }')\n",
    "print(f'to  : {real_pred.max().strftime(\"%d-%m-%Y\") }')\n",
    "\n",
    "print(f'      {real_pred.nunique()} days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(y_test, y_pred_test, mod):\n",
    "    \"\"\"Generated true vs. predicted values and residual scatter plot for models\n",
    "\n",
    "    Args:\n",
    "        y_test (array): true values for y_test\n",
    "        y_pred_test (array): predicted values of model for y_test\n",
    "    \"\"\"     \n",
    "    # Calculate residuals\n",
    "    residuals = y_test - y_pred_test\n",
    "    \n",
    "    # Plot real vs. predicted values \n",
    "    fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "    plt.subplots_adjust(right=1)\n",
    "    plt.suptitle(mod)\n",
    "    \n",
    "    ax[0].scatter(y_pred_test, y_test, color=\"#FF5A36\", alpha=0.7)\n",
    "    ax[0].plot([-400, 350], [-400, 350], color=\"#193251\")\n",
    "    ax[0].set_title(\"True vs. predicted values\", fontsize=16)\n",
    "    ax[0].set_xlabel(\"predicted values\")\n",
    "    ax[0].set_ylabel(\"true values\")\n",
    "    #ax[0].set_xlim((y_pred_test.min()-10), (y_pred_test.max()+10))\n",
    "    #ax[0].set_ylim((y_test.min()-40), (y_test.max()+40))\n",
    "    \n",
    "    ax[1].scatter(y_pred_test, residuals, color=\"#FF5A36\", alpha=0.7)\n",
    "    ax[1].plot([-400, 350], [0,0], color=\"#193251\")\n",
    "    ax[1].set_title(\"Residual Scatter Plot\", fontsize=16)\n",
    "    ax[1].set_xlabel(\"predicted values\")\n",
    "    ax[1].set_ylabel(\"residuals\")\n",
    "    #ax[1].set_xlim((y_pred_test.min()-10), (y_pred_test.max()+10))\n",
    "    #ax[1].set_ylim((residuals.min()-10), (residuals.max()+10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predN = pred.query('Date >= datetime.date(2021, 11,1)').sort_values('Date').sort_values('SecuritiesCode') \n",
    "realN =  real.query('Date >= datetime.date(2021, 11,1)').sort_values('Date').sort_values('SecuritiesCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = predN.query('Model ==@mod').sort_values('Date').sort_values('SecuritiesCode')\n",
    "# df_array=np.array(df.ad_Close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = predN.query('Model ==\"linear\"').sort_values('Date').sort_values('SecuritiesCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rea = np.array(realN.ad_Close)\n",
    "# pre = np.array(df.ad_Close)\n",
    "# residual = np.subtract(rea, pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rea = np.array(realN.ad_Close)\n",
    "for mod in predN.Model.unique():\n",
    "    df = predN.query('Model ==@mod').sort_values('Date').sort_values('SecuritiesCode')\n",
    "    pre = np.array(df.ad_Close)\n",
    "    error_analysis(rea, pre, mod)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> next evaluate"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e59dc4903522b6bd625aac9b906fbe96a3134871878cc11f65b8580a1e47af4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
